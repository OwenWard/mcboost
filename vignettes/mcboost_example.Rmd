---
title: "MCBoost - Health Survey Example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MCBoost - Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(tidyverse)
library(purrr)
library(PracTools)
library(randomForest)
library(neuralnet)
library(formattable)
library(mlr3)
library(mlr3learners)
library(mcboost)
```

## Data and Setup

This example presents a typical use-case of MCBoost with data from a health survey. The goal is to post-process two inital prediction models for multi-accuracy using different flavors of MCBoost, and to eventually compare the naive and post-processed predictors overall and for subpopulations. 

We use data derived from the National Health Interview Survey (NHIS 2003), which includes demographic and health-related variables for 21,588 individuals. This data can directly be included from the `PracTools` package.

```{r}
data(nhis.large)
?nhis.large
```

In the following, our outcome of interest is whether an individual is covered by any type of health insurance (`notcov`, 1 = not covered, 0 = covered). We additionally prepare two sets of variables:

- predictor variables (age, parents in household, education, income, employment status, physical or other limitations)
- subpopulation variables (sex, hispanic ethnicity, race)

The second set of variables will not be used for training the initial prediction models, but will be our focus when it comes to evaluating prediction performance for subgroups.

```{r}
categorical <- c("age.grp", "parents", "educ", "inc.grp", "doing.lw", "limited", "sex", "hisp", "race")

nhis <- nhis.large %>%
  mutate_at(categorical, as_factor) %>%
  mutate_at(categorical, fct_explicit_na) %>%
  drop_na(notcov) %>%
  select(all_of(categorical), notcov, svywt, ID)

nhis$notcov <- factor(ifelse(nhis$notcov == 1, "notcov", "cov"))

nhis_enc <- data.frame(model.matrix(notcov ~ ., data = nhis)[,-1])
nhis_enc$notcov <- nhis$notcov
nhis_enc$sex <- nhis$sex
nhis_enc$hisp <- nhis$hisp
nhis_enc$race <- nhis$race
nhis_enc$inv_wt <- (1 / nhis$svywt)^3
```

The pre-processed NHIS data will be split into three datasets: 

- A training set for training the initial prediction models
- An auditing set for post-processing the initial models with MCBoost
- A test set for model evaluation

To increase the difficulty of the prediction task, we sample from the NHIS data such that the prevalence of demographic subgroups in the test data differs from their prevalence in the training and auditing data. This is achieved by employing weighted sampling from NHIS.

```{r}
test <- nhis_enc %>% slice_sample(prop = 0.3, weight_by = inv_wt)

nontest_g <- nhis_enc %>% anti_join(test, by = "ID")

train_g <- nontest_g %>% slice_sample(prop = 0.6)

post <- nontest_g %>% anti_join(train_g, by = "ID") %>% select(-ID, -svywt, -inv_wt, -c(sex:race))

train <- train_g %>% select(-ID, -svywt, -inv_wt, -c(sex:race), -c(sex2:race3))
```

As a result, non-hispanic white individuals are overrepresented and hispanic individuals are underrepresented in both the training and auditing set, compared to their prevalence in the test set.

```{r}
train_g %>% summarise_at(vars(sex2:race3), mean)
```

```{r}
post %>% summarise_at(vars(sex2:race3), mean)
```

```{r}
test %>% summarise_at(vars(sex2:race3), mean)
```

## Initial Prediction Models

We use two initial models for predicting healthcare coverage with the training set. First, we use a random forest with the default settings of the `randomForest` package. 

```{r}
set.seed(23)
rf <- randomForest(notcov ~ ., 
                   data = train)
```

Second, we train a neural network with two hidden layers, again rather naively with little tweaking.

```{r}
nnet <- neuralnet(notcov ~ ., 
                  hidden = c(10, 2),
                  linear.output = FALSE,
                  err.fct = 'ce',
                  threshold = 0.25,
                  lifesign = 'full',
                  data = train)
```

## MCBoost Auditing

We prepare two functions that allow us to pass the predictions of both models to MCBoost for post-processing.

```{r}
init_rf = function(data) {
  predict(rf, data, type = "prob")[, 2]
}

init_nnet = function(data) {
  predict(nnet, data)[, 2]
}
```

To showcase different use cases of MCBoost, we prepare two post-processing data sets based on the auditing set. The first set includes only the predictor variables that were used by the initial models, whereas the second set will allow post-processing based on our demographic subgroups of interest (sex, hispanic ethnicity, race).   

```{r}
d1 <- select(post, -notcov)
d2 <- select(d1, -c(sex2:race3))
l <- 1 - one_hot(post$notcov)
```

We initialize custom auditors for MCBoost. Ridge regression and lasso regression with small penalties on model complexity, and a subpop-fitter with a fixed set of subpopulations. 

```{r}
ridge = LearnerResidualFitter$new(lrn("regr.glmnet", alpha = 0, lambda = 2 / nrow(post)))

lasso = LearnerResidualFitter$new(lrn("regr.glmnet", alpha = 1, lambda = 2 / nrow(post)))

pops = SubpopFitter$new(list("sex2", "hisp2", "hisp3", "hisp4", "race2", "race3"))
```

The ridge and lasso regressions will only be given access to the initial predictor variables when post-processing the random forest and neural net predictions with the auditing data. In addition, we guide the subpop-fitters to audit the initial predictions explicitly on the outlined subpopulations (sex, hispanic ethnicity, race). In summary, we have:

- `mc1`: Random forest, post-processed with ridge regression and the initial set of predictor variables 
- `mc2`: Random forest, post-processed with a fixed set of subpopulations
- `mc3`: Neural net, post-processed with lasso regression and the initial set of predictor variables 
- `mc4`: Neural net, post-processed with a fixed set of subpopulations

```{r}
mc1 = MCBoost$new(init_predictor = init_rf, 
                 subpop_fitter = ridge,
                 multiplicative = TRUE,
                 partition = TRUE,
                 max_iter = 10)
mc1$multicalibrate(d2, l)

mc2 = MCBoost$new(init_predictor = init_rf, 
                 subpop_fitter = pops,
                 partition = TRUE,
                 max_iter = 10)
mc2$multicalibrate(d1, l)

mc3 = MCBoost$new(init_predictor = init_nnet, 
                 subpop_fitter = lasso,
                 multiplicative = TRUE,
                 partition = TRUE,
                 max_iter = 10)
mc3$multicalibrate(d2, l)

mc4 = MCBoost$new(init_predictor = init_nnet, 
                 subpop_fitter = pops,
                 partition = TRUE,
                 max_iter = 10)
mc4$multicalibrate(d1, l)
```

## Model Evaluation

```{r}
test$rf <- predict(rf, newdata = test, type = "prob")[, 2]
test$nnet <- predict(nnet, newdata = test)[, 2]
test$mc1 <- mc1$predict_probs(test)
test$mc2 <- mc2$predict_probs(test)
test$mc3 <- mc3$predict_probs(test)
test$mc4 <- mc4$predict_probs(test)

test$c_rf <- round(test$rf)
test$c_nnet <- round(test$nnet)
test$c_mc1 <- round(test$mc1)
test$c_mc2 <- round(test$mc2)
test$c_mc3 <- round(test$mc3)
test$c_mc4 <- round(test$mc4)
test$label <- 1 - one_hot(test$notcov)
```

```{r}
mean(test$c_rf == test$label)
mean(test$c_mc1 == test$label)
mean(test$c_mc2 == test$label)

mean(test$c_nnet == test$label)
mean(test$c_mc3 == test$label)
mean(test$c_mc4 == test$label)
```

```{r}
test <- test %>% 
  mutate(sex_hisp = group_indices(., sex, hisp),
         sex_race = group_indices(., sex, race),
         hisp_race = group_indices(., hisp, race))

grouping_vars <- c("sex", "hisp", "race", "sex_hisp", "sex_race", "hisp_race")

eval <- map(grouping_vars, group_by_at, .tbl = test) %>%
  map(summarise,
      'accuracy_rf' = mean(c_rf == label),
      'accuracy_mc1' = mean(c_mc1 == label),
      'accuracy_mc2' = mean(c_mc2 == label),
      'accuracy_nnet' = mean(c_nnet == label),
      'accuracy_mc3' = mean(c_mc3 == label),
      'accuracy_mc4' = mean(c_mc4 == label),
      'bias_rf' = abs(mean(rf) - mean(label))*100,
      'bias_mc1' = abs(mean(mc1) - mean(label))*100,
      'bias_mc2' = abs(mean(mc2) - mean(label))*100,
      'bias_nnet' = abs(mean(nnet) - mean(label))*100,
      'bias_mc3' = abs(mean(mc3) - mean(label))*100,
      'bias_mc4' = abs(mean(mc4) - mean(label))*100,
      'size' = n()) %>%
  bind_rows()
```

```{r}
eval %>%
  arrange(desc(size)) %>%
  select(size, accuracy_rf:accuracy_mc4) %>%
  round(., digits = 3) %>%
  formattable(., lapply(1:nrow(eval), function(row) {
  area(row, col = 2:7) ~ color_tile("transparent", "lightgreen")
    }))
```

```{r}
eval %>%
  arrange(desc(size)) %>%
  select(size, bias_rf:bias_mc4) %>%
  round(., digits = 3) %>%
  formattable(., lapply(1:nrow(eval), function(row) {
  area(row, col = 2:7) ~ color_tile("lightgreen", "transparent")
    }))
```
